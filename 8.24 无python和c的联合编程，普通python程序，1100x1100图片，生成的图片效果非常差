
8.24 无python和c的联合编程，普通python程序，1100x1100图片，生成的图片效果非常差

主程序

# coding:utf8
import os
import ipdb
import torch as t
import torchvision as tv
import tqdm
from model import NetG, NetD
from torchnet.meter import AverageValueMeter

import matplotlib.pyplot as plt
import numpy as np
import cv2

list_file = "./picture_presolve/pos_y.txt"
with open(list_file) as f:
    lines = f.readlines()
    # print(lines)
    line = lines[0].strip().split(".")

line=list(map(lambda x:float(x), line[:-1]))
# MI=np.min(line)
# MA=np.max(line)
mean=np.mean(line)
std=np.std(line)
line=t.Tensor(line)
line=(line-mean)/std

# line=(line-MI)/(MA-MI)
# print((line-MI)/(MA-MI))
# print(line)
# input()

# a=[1,2,3]
# print(np.mean(a),np.std(a))
# print(np.sqrt(2/3))
# input()

# print(len(line)-256*100)
# a=np.random.randint(0,(len(line)-1)-256*100)
# print(a)

# res = list(map(lambda x:float(x), line[a:a+256*100]))
#
# res1=t.tensor(res,dtype=t.float32).reshape(256,100,1,1)
# print(res1)
# input()

# print(line[0:-1])


class Config(object):
    data_path = 'picture_presolve/picture2/'  # 数据集存放路径
    num_workers = 4  # 多进程加载数据所用的进程数
    # image_size = 96  # 图片尺寸
    # image_size = 288
    # batch_size = 256
    image_size=1100
    batch_size=1
    max_epoch = 500
    lr1 = 2e-4  # 生成器的学习率
    lr2 = 2e-4  # 判别器的学习率
    beta1 = 0.5  # Adam优化器的beta1参数
    gpu = True  # 是否使用GPU
    nz = 100  # 噪声维度
    ngf = 64  # 生成器feature map数
    ndf = 64  # 判别器feature map数

    save_path = 'imgs/'  # 生成图片保存路径

    vis = True  # 是否使用visdom可视化
    env = 'GAN'  # visdom的env
    plot_every = 20  # 每间隔20 batch，visdom画图一次

    debug_file = '/tmp/debuggan'  # 存在该文件则进入debug模式
    d_every = 1  # 每1个batch训练一次判别器
    g_every = 5  # 每5个batch训练一次生成器
    save_every = 10  # 没10个epoch保存一次模型
    netd_path = 'checkpoints/netd_199.pth'  # 'checkpoints/netd_.pth' #预训练模型
    netg_path = 'checkpoints/netg_199.pth'  # 'checkpoints/netg_211.pth'

    # 只测试不训练
    gen_img = 'result.png'
    # 从512张生成的图片中保存最好的64张
    gen_num = 64
    gen_search_num = 512
    gen_mean = 0  # 噪声的均值
    gen_std = 1  # 噪声的方差


opt = Config()
from ctypes import *  # cdll, c_int

class callsubBuf(object):
    def __init__(self):
        self.obj = lib.subBuf_new()

    def callcursubBuf(self, data, num, outData):
        lib.subBuf_sub(self.obj, data, num, outData)

    def call_call(self, data1, x, y, data2, data3):
        lib.call_call_call(self.obj, data1, x, y, data2, data3)


def train(**kwargs):
    for k_, v_ in kwargs.items():
        setattr(opt, k_, v_)

    device = t.device('cuda') if opt.gpu else t.device('cpu')
    if opt.vis:
        from visualize import Visualizer
        vis = Visualizer(opt.env)

    # 数据
    transforms = tv.transforms.Compose([
        # tv.transforms.Resize(opt.image_size),
        # tv.transforms.CenterCrop(opt.image_size),
        tv.transforms.ToTensor(),
        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)
    dataloader = t.utils.data.DataLoader(dataset,
                                         batch_size=opt.batch_size,
                                         shuffle=False,
                                         num_workers=opt.num_workers,
                                         drop_last=True
                                         )

    # 网络
    netg, netd = NetG(opt), NetD(opt)
    map_location = lambda storage, loc: storage
    # if opt.netd_path:
    #     netd.load_state_dict(t.load(opt.netd_path, map_location=map_location))
    # if opt.netg_path:
    #     netg.load_state_dict(t.load(opt.netg_path, map_location=map_location))
    netd.to(device)
    netg.to(device)

    # 定义优化器和损失
    optimizer_g = t.optim.Adam(netg.parameters(), opt.lr1, betas=(opt.beta1, 0.999))
    optimizer_d = t.optim.Adam(netd.parameters(), opt.lr2, betas=(opt.beta1, 0.999))
    criterion = t.nn.BCELoss().to(device)

    # 真图片label为1，假图片label为0
    # noises为生成网络的输入
    true_labels = t.ones(opt.batch_size).to(device)
    fake_labels = t.zeros(opt.batch_size).to(device)
    fix_noises = t.randn(opt.batch_size, opt.nz, 1, 1).to(device)
    noises = t.randn(opt.batch_size, opt.nz, 1, 1).to(device)

    errord_meter = AverageValueMeter()
    errorg_meter = AverageValueMeter()

    iii=0
    epochs = range(opt.max_epoch)
    for epoch in iter(epochs):
        for ii, (img, _) in tqdm.tqdm(enumerate(dataloader)):
            # print(t.tensor(img[0].cpu(), dtype=t.float32)[0,150,50:200])
            # print(img[0].shape)
            # input()
            # plt.imshow(img[0,1,:,:])
            # plt.pause(0.01)


            lib = cdll.LoadLibrary('./c_c++_loss/libmathBuf.so')
            print(lib)
            # plt.imshow(t.tensor(img[0].cpu(),dtype=t.float32).permute(1,2,0)[:,:,1])
            # plt.show()


            # plt.imshow(t.tensor(img[23].cpu(), dtype=t.float32).permute(1, 2, 0))
            # plt.show()
            # input()

            # # plt.imshow(t.Tensor.cpu(fix_fake_imgs))
            # plt.pause(0.01)
            # # plt.imshow(t.tensor(img[0], dtype=t.float32).permute(1, 2 , 0))
            # # plt.pause(0.01)
            # # # input()
            real_img = img.to(device)
            # print(t.tensor(real_img,dtype=t.float32).shape)

            # for i in range(25):
            #     print(t.tensor(real_img[i].cpu(),dtype=t.float32))
            #     plt.imshow(t.tensor(real_img[i].cpu(),dtype=t.float32).permute(1,2,0))
            #     plt.show()
            # input()

            if ii % opt.d_every == 0:
                # 训练判别器
                optimizer_d.zero_grad()
                ## 尽可能的把真图片判别为正确
                output = netd(real_img)
                # print(output)
                # print(output.size())
                error_d_real = criterion(output, true_labels)
                error_d_real.backward()

                ## 尽可能把假图片判别为错误
                # a1=np.random.randint(0,(len(line)-1)-opt.batch_size*opt.nz)
                # res1 = list(map(lambda x:float(x), line[a1:a1+opt.batch_size*opt.nz]))
                # res11=t.tensor(res1,dtype=t.float32).reshape(opt.batch_size,opt.nz,1,1)
                a1 = np.random.randint(0, len(line) - opt.batch_size * opt.nz)
                res1 = line[a1:a1 + opt.batch_size * opt.nz].reshape(opt.batch_size, opt.nz, 1, 1)
                # print(res1)
                # input()
                # res11 = t.tensor(res1, dtype=t.float32).reshape(opt.batch_size, opt.nz, 1, 1)
                # print(res11)
                # res11 = t.tensor(res1, dtype=t.float32).normal_(M,S).reshape(opt.batch_size, opt.nz, 1, 1)
                # print(res11)
                # input()
                # print(res11)
                noises.data.copy_(res1)
                # noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))
                fake_img = netg(noises).detach()  # 根据噪声生成假图
                output = netd(fake_img)
                error_d_fake = criterion(output, fake_labels)
                error_d_fake.backward()
                optimizer_d.step()

                error_d = error_d_fake + error_d_real

                errord_meter.add(error_d.item())
                print(errord_meter.value())
                vis.plot('errord', errord_meter.value()[0])

            if ii % opt.g_every == 0:
                # 训练生成器
                optimizer_g.zero_grad()

                # a2=np.random.randint(0,(len(line)-1)-opt.batch_size*opt.nz)
                # res2 = list(map(lambda x:float(x), line[a2:a2+opt.batch_size*opt.nz]))
                # res22=t.tensor(res2,dtype=t.float32).reshape(opt.batch_size,opt.nz,1,1)


                a2 = np.random.randint(0, len(line) - opt.batch_size * opt.nz)
                res2 = line[a2:a2 + opt.batch_size * opt.nz].reshape(opt.batch_size, opt.nz, 1, 1)
                noises.data.copy_(res2)


                # noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))
                fake_img = netg(noises)
                output = netd(fake_img)
                error_g = criterion(output, true_labels)
                error_g.backward()
                optimizer_g.step()
                errorg_meter.add(error_g.item())

            if opt.vis and ii % opt.plot_every == opt.plot_every - 1:
                ## 可视化
                if os.path.exists(opt.debug_file):
                    ipdb.set_trace()

                # a3=np.random.randint(0,(len(line)-1)-opt.batch_size*opt.nz)
                # res3 = list(map(lambda x:float(x), line[a3:a3+opt.batch_size*opt.nz]))
                # res33=t.tensor(res3,dtype=t.float32).reshape(opt.batch_size,opt.nz,1,1)

                a3 = np.random.randint(0, len(line) - opt.batch_size * opt.nz)
                res3 = line[a3:a3 + opt.batch_size * opt.nz].reshape(opt.batch_size, opt.nz, 1, 1)

                fix_noises.data.copy_(res3)

                fix_fake_imgs = netg(fix_noises)


                # plt.imshow(t.tensor(fix_fake_imgs[1,:,:].cpu(), dtype=t.float32))
                # plt.imshow(t.tensor(fix_fake_imgs[0].cpu(),dtype=t.float32).permute(1,2,0))
                # plt.imshow(t.tensor(fix_fake_imgs[0].cpu(), dtype=t.float32).permute(1, 2, 0)[:,:,1])
                # plt.show()



                imgg=t.tensor(fix_fake_imgs[0].cpu(), dtype=t.float32).permute(1, 2, 0)[:, :, 1]
                plt.imsave('./imgs/' + str(iii) + '.jpg', imgg)
                iii += 1

                # # # plt.imshow(t.Tensor.cpu(fix_fake_imgs))
                # plt.pause(0.01)

                vis.images(fix_fake_imgs.detach().cpu().numpy()[:64] * 0.5 + 0.5, win='fixfake')
                vis.images(real_img.data.cpu().numpy()[:64] * 0.5 + 0.5, win='real')
                vis.plot('errord', errord_meter.value()[0])
                vis.plot('errorg', errorg_meter.value()[0])

        if (epoch + 1) % opt.save_every == 0:
            # 保存模型、图片
            tv.utils.save_image(fix_fake_imgs.data[:64], '%s/%s.png' % (opt.save_path, epoch), normalize=True,
                                range=(-1, 1))
            t.save(netd.state_dict(), 'checkpoints/netd_%s.pth' % epoch)
            t.save(netg.state_dict(), 'checkpoints/netg_%s.pth' % epoch)
            errord_meter.reset()
            errorg_meter.reset()


@t.no_grad()
def generate(**kwargs):
    """
    随机生成动漫头像，并根据netd的分数选择较好的
    """
    for k_, v_ in kwargs.items():
        setattr(opt, k_, v_)

    device = t.device('cuda') if opt.gpu else t.device('cpu')

    netg, netd = NetG(opt).eval(), NetD(opt).eval()

    # a4 = np.random.randint(0, (len(line) - 1) - opt.batch_size * opt.nz)
    # res4 = list(map(lambda x: float(x), line[a4:a4 + opt.batch_size * opt.nz]))
    # res44 = t.tensor(res4, dtype=t.float32).reshape(opt.batch_size, opt.nz, 1, 1)
    # fix_noises.data.copy_(res44)

    noises = t.randn(opt.gen_search_num, opt.nz, 1, 1).normal_(opt.gen_mean, opt.gen_std)
    noises = noises.to(device)

    map_location = lambda storage, loc: storage
    netd.load_state_dict(t.load(opt.netd_path, map_location=map_location))
    netg.load_state_dict(t.load(opt.netg_path, map_location=map_location))
    netd.to(device)
    netg.to(device)

    # 生成图片，并计算图片在判别器的分数
    fake_img = netg(noises)
    # print(fake_img.shape)
    # plt.imshow(fake_img[0])
    # plt.show()
    scores = netd(fake_img).detach()

    # 挑选最好的某几张
    indexs = scores.topk(opt.gen_num)[1]
    result = []
    for ii in indexs:
        print("*")
        x = t.tensor(fake_img.data[ii], dtype=t.float32).permute(1, 2, 0)

        result.append(fake_img.data[ii])
        plt.imshow(x)
        plt.show()
    # 保存图片
    tv.utils.save_image(t.stack(result), opt.gen_img, normalize=True, range=(-1, 1))


if __name__ == '__main__':
    import fire

    fire.Fire()
    train(gpu=True, vis=True)
    # generate(gpu=False, vis=True)
#




from PIL import Image
import cv2
import matplotlib.pyplot as plt
# import torch as t
# a=t.Tensor(300,309)
# b=a.resize(96,96)
# print(b)


# a=cv2.imread("./picture_presolve/picture3/picture/ZHJGhuibian-00001.png")
# # a=Image.open("./picture_presolve/picture3/picture/ZHJGhuibian-00001.png")
# print(a)
#
# b=a.resize(96,96)
# import torch as t
# c=t.tensor(b,dtype=t.float32)
# print(c)
# # a=a.resize((384,384),1)



# a1,b1,c1=cv2.split(a)
# print(a.shape)
# a=cv2.merge([c1,b1,a1])
# plt.imshow(a)
# plt.show()




网络

# # coding:utf8
# from torch import nn
#
#
# class NetG(nn.Module):
#     """
#     生成器定义
#     """
#
#     def __init__(self, opt):
#         super(NetG, self).__init__()
#         ngf = opt.ngf  # 生成器feature map数
#
#         self.main = nn.Sequential(
#             # 输入是一个nz维度的噪声，我们可以认为它是一个1*1*nz的feature map
#             nn.ConvTranspose2d(opt.nz, ngf * 8, 4, 1, 0, bias=False),
#             nn.BatchNorm2d(ngf * 8),
#             nn.ReLU(True),
#             # 上一步的输出形状：(ngf*8) x 4 x 4
#
#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
#             nn.BatchNorm2d(ngf * 4),
#             nn.ReLU(True),
#             # 上一步的输出形状： (ngf*4) x 8 x 8
#
#             nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
#             nn.BatchNorm2d(ngf * 2),
#             nn.ReLU(True),
#             # 上一步的输出形状： (ngf*2) x 16 x 16
#
#             nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
#             nn.BatchNorm2d(ngf),
#             nn.ReLU(True),
#             # 上一步的输出形状：(ngf) x 32 x 32
#
#             nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),
#             nn.Tanh()  # 输出范围 -1~1 故而采用Tanh
#             # 输出形状：3 x 96 x 96
#         )
#
#     def forward(self, input):
#         return self.main(input)


# class NetD(nn.Module):
#     """
#     判别器定义
#     """
#
#     def __init__(self, opt):
#         super(NetD, self).__init__()
#         ndf = opt.ndf
#         self.main = nn.Sequential(
#
#
#         # 输入 3 x 96 x 96
#         nn.Conv2d(3, ndf, 5, 3, 1, bias=False),
#         nn.LeakyReLU(0.2, inplace=True),
#         # 输出 (ndf) x 32 x 32
#
#         nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
#         nn.BatchNorm2d(ndf * 2),
#         nn.LeakyReLU(0.2, inplace=True),
#         # 输出 (ndf*2) x 16 x 16
#
#         nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
#         nn.BatchNorm2d(ndf * 4),
#         nn.LeakyReLU(0.2, inplace=True),
#         # 输出 (ndf*4) x 8 x 8
#
#         nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
#         nn.BatchNorm2d(ndf * 8),
#         nn.LeakyReLU(0.2, inplace=True),
#         # 输出 (ndf*8) x 4 x 4
#
#         nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
#         nn.Sigmoid()  # 输出一个数(概率)
#  )
#
#
#     def forward(self, input):
#
#
#         return self.main(input).view(-1)
#


# coding:utf8
from torch import nn


class NetG(nn.Module):
    """
    生成器定义
    """

    def __init__(self, opt):
        super(NetG, self).__init__()
        ngf = opt.ngf  # 生成器feature map数

        self.main = nn.Sequential(
            # 输入是一个nz维度的噪声，我们可以认为它是一个1*1*nz的feature map
            nn.ConvTranspose2d(opt.nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # 上一步的输出形状：(ngf*8) x 4 x 4

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # 上一步的输出形状： (ngf*4) x 8 x 8

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # 上一步 16 x 16
            nn.ConvTranspose2d(ngf * 2, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # 上一步 32 x 32

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # 上一步 64 x 64

            nn.ConvTranspose2d(ngf * 2, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # 上一步 128 x 128

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # 上一步 256 x 256

            nn.ConvTranspose2d(ngf * 2, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # 上一步 512 x 512

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),  # 1024 x 1024
            # 上一步的输出形状： (ngf*2) x 16 x 16

            # nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 上一步的输出形状：(ngf) x 32 x 32

            nn.ConvTranspose2d(ngf * 2, 3, 77, 1, 0, bias=False),
            nn.Tanh()
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1027
            #
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            #
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.BatchNorm2d(ngf),
            # nn.ReLU(True),
            # # 1030
            # nn.ConvTranspose2d(ngf, ngf, 4, 1, 0, bias=False),
            # nn.Tanh()
            # # 1030

            # nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),
            # nn.Tanh()  # 输出范围 -1~1 故而采用Tanh
            # 输出形状：3 x 96 x 96
        )

    def forward(self, input):
        return self.main(input)


#  self
class NetD(nn.Module):
    """
    判别器定义
    """

    def __init__(self, opt):
        super(NetD, self).__init__()
        ndf = opt.ndf

        # self.main = nn.Sequential(

        # self.conv1 = nn.Conv2d(3, 3, 5, 3, 1, bias=False)
        # self.lr1 = nn.LeakyReLU(0.2, inplace=True)

        self.conv2 = nn.Conv2d(3, ndf, 5, 3, 1, bias=False)
        self.lr2 = nn.LeakyReLU(0.2, inplace=True)

        # 输入 3 x 96 x 96
        self.conv3 = nn.Conv2d(ndf, ndf, 5, 3, 1, bias=False)
        self.lr3 = nn.LeakyReLU(0.2, inplace=True)
        # 输出 (ndf) x 32 x 32

        self.conv4 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(ndf * 2)
        self.lr4 = nn.LeakyReLU(0.2, inplace=True)
        # 输出 (ndf*2) x 16 x 16

        self.conv5 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False)
        self.bn2 = nn.BatchNorm2d(ndf * 4)
        self.lr5 = nn.LeakyReLU(0.2, inplace=True)
        # 输出 (ndf*4) x 8 x 8

        self.conv6 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False)
        self.bn3 = nn.BatchNorm2d(ndf * 8)
        self.lr6 = nn.LeakyReLU(0.2, inplace=True)
        # 输出 (ndf*8) x 4 x 4

        self.conv7 = nn.Conv2d(ndf * 8, 1, 15, 1, 0, bias=False)
        self.sigmoid = nn.Sigmoid()  # 输出一个数(概率)

        # )

    def forward(self, input):
        # input = self.conv1(input)
        # input = self.lr1(input)

        input = self.conv2(input)
        input = self.lr2(input)

        input = self.conv3(input)
        input = self.lr3(input)

        input = self.conv4(input)
        input = self.bn1(input)
        input = self.lr4(input)

        input = self.conv5(input)
        input = self.bn2(input)
        input = self.lr5(input)

        input = self.conv6(input)
        input = self.bn3(input)
        input = self.lr6(input)

        # print("self.conv6", input.shape)

        input = self.conv7(input)
        input = self.sigmoid(input)
        # print("self.conv7", input.shape)

        return input.view(-1)

        # return self.main(input).view(-1)


